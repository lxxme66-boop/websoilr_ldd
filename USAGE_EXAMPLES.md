# æ™ºèƒ½QAç”Ÿæˆç³»ç»Ÿ - ä½¿ç”¨ç¤ºä¾‹

æœ¬æ–‡æ¡£æä¾›è¯¦ç»†çš„ä½¿ç”¨ç¤ºä¾‹ï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹æ™ºèƒ½QAç”Ÿæˆç³»ç»Ÿã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼

```bash
# ä½¿ç”¨äº¤äº’å¼å¿«é€Ÿå¼€å§‹è„šæœ¬
chmod +x quick_start.sh
./quick_start.sh
```

è¿™å°†å¯åŠ¨ä¸€ä¸ªäº¤äº’å¼èœå•ï¼Œå¼•å¯¼æ‚¨å®Œæˆæ•´ä¸ªæµç¨‹ã€‚

### 2. ä¸€é”®å®Œæ•´æµæ°´çº¿

```bash
# å¤„ç†å•ä¸ªPDFæ–‡ä»¶å¤¹
python run_pipeline.py \
    --mode full_pipeline \
    --input_path data/semiconductor_papers \
    --output_path data/results \
    --domain semiconductor
```

## ğŸ“‹ è¯¦ç»†ä½¿ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šåŠå¯¼ä½“è®ºæ–‡QAç”Ÿæˆ

å‡è®¾æ‚¨æœ‰ä¸€æ‰¹å…³äºIGZOææ–™çš„ç ”ç©¶è®ºæ–‡ï¼š

```bash
# ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡æ•°æ®
mkdir -p data/semiconductor_papers
# å°†PDFæ–‡ä»¶æ”¾å…¥è¯¥ç›®å½•

# ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œå®Œæ•´æµæ°´çº¿
python run_pipeline.py \
    --mode full_pipeline \
    --input_path data/semiconductor_papers \
    --output_path data/semiconductor_results \
    --domain semiconductor \
    --batch_size 50 \
    --quality_threshold 0.8 \
    --enhanced_quality \
    --verbose

# ç»“æœå°†ä¿å­˜åœ¨ data/semiconductor_results/pipeline_YYYYMMDD_HHMMSS/ ä¸­
```

**é¢„æœŸè¾“å‡ºç»“æ„ï¼š**
```
data/semiconductor_results/pipeline_20241220_143022/
â”œâ”€â”€ 01_retrieved/          # æ•°æ®å¬å›ç»“æœ
â”œâ”€â”€ 02_cleaned/            # æ¸…ç†åçš„æ•°æ®
â”œâ”€â”€ 03_qa_generated/       # ç”Ÿæˆçš„QAå¯¹
â”œâ”€â”€ 04_quality_checked/    # è´¨é‡æ£€æŸ¥åçš„æ•°æ®
â””â”€â”€ 05_final/             # æœ€ç»ˆæŠ¥å‘Šå’Œç»Ÿè®¡
```

### æ¡ˆä¾‹2ï¼šå…‰å­¦é¢†åŸŸæ‰¹é‡å¤„ç†

å¤„ç†å¤šä¸ªå…‰å­¦ç›¸å…³çš„PDFæ–‡ä»¶å¤¹ï¼š

```bash
# å‡†å¤‡å¤šä¸ªæ–‡ä»¶å¤¹
mkdir -p data/optics/{laser_papers,spectroscopy_papers,photonics_papers}

# æ‰¹é‡å¤„ç†
./batch_process.sh \
    --output data/optics_results \
    --domain optics \
    --batch-size 100 \
    --quality 0.75 \
    --jobs 3 \
    data/optics/laser_papers \
    data/optics/spectroscopy_papers \
    data/optics/photonics_papers
```

### æ¡ˆä¾‹3ï¼šåˆ†æ­¥éª¤å¤„ç†ï¼ˆé€‚åˆå¤§æ•°æ®é‡ï¼‰

å½“æ•°æ®é‡å¾ˆå¤§æ—¶ï¼Œå»ºè®®åˆ†æ­¥éª¤å¤„ç†ï¼š

```bash
# æ­¥éª¤1ï¼šæ•°æ®å¬å›
python run_pipeline.py \
    --mode retrieval \
    --input_path data/large_dataset \
    --output_path data/retrieved \
    --selected_task_number 5000 \
    --batch_size 200

# æ­¥éª¤2ï¼šæ•°æ®æ¸…ç†
python run_pipeline.py \
    --mode cleaning \
    --input_path data/retrieved/total_response.pkl \
    --output_path data/cleaned

# æ­¥éª¤3ï¼šQAç”Ÿæˆ
python run_pipeline.py \
    --mode qa_generation \
    --input_path data/cleaned/total_response.json \
    --output_path data/qa_results \
    --domain semiconductor \
    --pool_size 150

# æ­¥éª¤4ï¼šè´¨é‡æ§åˆ¶
python run_pipeline.py \
    --mode quality_control \
    --input_path data/qa_results/results_343.json \
    --output_path data/final_results
```

## ğŸ”§ é«˜çº§é…ç½®ç¤ºä¾‹

### è‡ªå®šä¹‰é…ç½®æ–‡ä»¶

åˆ›å»ºä¸“é—¨çš„é…ç½®æ–‡ä»¶ `my_config.json`ï¼š

```json
{
  "api": {
    "ark_url": "http://your-api-server:8080/v1",
    "api_key": "your-api-key"
  },
  "processing": {
    "batch_size": 150,
    "quality_threshold": 0.8,
    "selected_task_number": 2000
  },
  "domains": {
    "my_domain": {
      "prompts": [3431, 3432],
      "keywords": ["è‡ªå®šä¹‰å…³é”®è¯1", "è‡ªå®šä¹‰å…³é”®è¯2"],
      "quality_criteria": "high"
    }
  }
}
```

ä½¿ç”¨è‡ªå®šä¹‰é…ç½®ï¼š

```bash
python run_pipeline.py \
    --config my_config.json \
    --mode full_pipeline \
    --input_path data/input \
    --output_path data/output \
    --domain my_domain
```

### æ€§èƒ½ä¼˜åŒ–é…ç½®

é’ˆå¯¹é«˜æ€§èƒ½æœåŠ¡å™¨çš„é…ç½®ï¼š

```bash
python run_pipeline.py \
    --mode full_pipeline \
    --input_path data/input \
    --output_path data/output \
    --batch_size 300 \
    --pool_size 200 \
    --selected_task_number 10000 \
    --domain semiconductor
```

## ğŸ” è´¨é‡æ§åˆ¶ç¤ºä¾‹

### åŸºç¡€è´¨é‡æ£€æŸ¥

```bash
# å¯¹ç°æœ‰QAæ•°æ®è¿›è¡Œè´¨é‡æ£€æŸ¥
python run_pipeline.py \
    --mode quality_control \
    --input_path data/qa_results/results_343.json \
    --output_path data/quality_checked \
    --verbose
```

### å¢å¼ºè´¨é‡æ£€æŸ¥

```bash
# ä½¿ç”¨å¢å¼ºè´¨é‡æ£€æŸ¥
python text_qa_generation/text_qa_generation.py \
    --check_task true \
    --enhanced_quality true \
    --quality_threshold 0.8 \
    --file_path data/qa_results/results_343.json
```

## ğŸ“Š ç»“æœåˆ†æç¤ºä¾‹

### æŸ¥çœ‹ç”Ÿæˆç»Ÿè®¡

```python
import json
import matplotlib.pyplot as plt

# åŠ è½½ç»“æœæ•°æ®
with open('data/results/pipeline_20241220_143022/05_final/pipeline_report.json', 'r') as f:
    report = json.load(f)

# æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
print("å¤„ç†ç»Ÿè®¡:")
for stage, stats in report['statistics'].items():
    print(f"- {stage}: {stats['data_count']} æ¡æ•°æ®")

# å¯è§†åŒ–è´¨é‡åˆ†å¸ƒï¼ˆéœ€è¦å®‰è£…matplotlibï¼‰
# qa_data = json.load(open('data/results/final_qa.json'))
# quality_scores = [item.get('quality_score', 0) for item in qa_data]
# plt.hist(quality_scores, bins=20)
# plt.xlabel('è´¨é‡åˆ†æ•°')
# plt.ylabel('æ•°é‡')
# plt.title('QAè´¨é‡åˆ†å¸ƒ')
# plt.show()
```

### å¯¼å‡ºç‰¹å®šæ ¼å¼

```python
import json

# åŠ è½½QAæ•°æ®
with open('data/results/qa_generated/results_343.json', 'r') as f:
    qa_data = json.load(f)

# å¯¼å‡ºä¸ºè®­ç»ƒæ ¼å¼
training_data = []
for item in qa_data:
    if 'qa_pairs' in item:
        for qa in item['qa_pairs']:
            training_data.append({
                'instruction': qa['question'],
                'output': qa['answer'],
                'reasoning': qa.get('reasoning', ''),
                'domain': 'semiconductor'
            })

# ä¿å­˜è®­ç»ƒæ•°æ®
with open('data/training_format.json', 'w', encoding='utf-8') as f:
    json.dump(training_data, f, ensure_ascii=False, indent=2)
```

## ğŸ› ï¸ æ•…éšœæ’é™¤ç¤ºä¾‹

### å†…å­˜ä¸è¶³é—®é¢˜

```bash
# å‡å°‘æ‰¹å¤„ç†å¤§å°
python run_pipeline.py \
    --mode full_pipeline \
    --input_path data/input \
    --output_path data/output \
    --batch_size 50 \
    --pool_size 50
```

### APIè°ƒç”¨å¤±è´¥

```bash
# æ£€æŸ¥APIè¿æ¥
curl -I http://0.0.0.0:8080/v1

# ä½¿ç”¨è¯•è¿è¡Œæ¨¡å¼æ£€æŸ¥é…ç½®
python run_pipeline.py \
    --mode full_pipeline \
    --input_path data/input \
    --output_path data/output \
    --dry_run
```

### æ•°æ®æ ¼å¼é—®é¢˜

```bash
# éªŒè¯è¾“å…¥æ•°æ®
python check_file.py --input data/input.json

# é‡æ–°æ¸…ç†æ•°æ®
python run_pipeline.py \
    --mode cleaning \
    --input_path data/raw/total_response.pkl \
    --output_path data/recleaned
```

## ğŸ“ˆ æ€§èƒ½ç›‘æ§ç¤ºä¾‹

### ç›‘æ§å¤„ç†è¿›åº¦

```bash
# åœ¨å¦ä¸€ä¸ªç»ˆç«¯ä¸­ç›‘æ§æ—¥å¿—
tail -f logs/pipeline.log

# ç›‘æ§ç³»ç»Ÿèµ„æº
htop
# æˆ–
watch -n 1 'ps aux | grep python'
```

### æ€§èƒ½åˆ†æ

```python
import json
import time
from datetime import datetime

def analyze_performance(log_file):
    """åˆ†æå¤„ç†æ€§èƒ½"""
    with open(log_file, 'r') as f:
        logs = f.readlines()
    
    # æå–æ—¶é—´æˆ³å’Œé˜¶æ®µä¿¡æ¯
    stages = []
    for line in logs:
        if 'å¼€å§‹' in line or 'å®Œæˆ' in line:
            # è§£ææ—¶é—´æˆ³å’Œé˜¶æ®µ
            # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„æ—¥å¿—è§£æé€»è¾‘
            pass
    
    return stages

# ä½¿ç”¨ç¤ºä¾‹
# performance_data = analyze_performance('logs/pipeline.log')
```

## ğŸ”„ è‡ªåŠ¨åŒ–ç¤ºä¾‹

### å®šæ—¶å¤„ç†è„šæœ¬

```bash
#!/bin/bash
# auto_process.sh - è‡ªåŠ¨åŒ–å¤„ç†è„šæœ¬

# è®¾ç½®è·¯å¾„
INPUT_DIR="/data/incoming_pdfs"
OUTPUT_DIR="/data/processed_results"
ARCHIVE_DIR="/data/archive"

# æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ–‡ä»¶
if [ "$(ls -A $INPUT_DIR)" ]; then
    echo "å‘ç°æ–°æ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†..."
    
    # åˆ›å»ºæ—¶é—´æˆ³ç›®å½•
    TIMESTAMP=$(date +%Y%m%d_%H%M%S)
    CURRENT_OUTPUT="$OUTPUT_DIR/$TIMESTAMP"
    
    # æ‰§è¡Œå¤„ç†
    python run_pipeline.py \
        --mode full_pipeline \
        --input_path "$INPUT_DIR" \
        --output_path "$CURRENT_OUTPUT" \
        --domain semiconductor \
        --batch_size 100
    
    # å½’æ¡£åŸæ–‡ä»¶
    mv "$INPUT_DIR"/* "$ARCHIVE_DIR/"
    
    echo "å¤„ç†å®Œæˆï¼Œç»“æœä¿å­˜åœ¨: $CURRENT_OUTPUT"
else
    echo "æ²¡æœ‰æ–°æ–‡ä»¶éœ€è¦å¤„ç†"
fi
```

### ç›‘æ§å’ŒæŠ¥è­¦

```python
import smtplib
from email.mime.text import MIMEText
import json
import os

def send_completion_email(report_file):
    """å¤„ç†å®Œæˆåå‘é€é‚®ä»¶é€šçŸ¥"""
    with open(report_file, 'r') as f:
        report = json.load(f)
    
    # æ„é€ é‚®ä»¶å†…å®¹
    subject = "QAç”Ÿæˆä»»åŠ¡å®Œæˆ"
    body = f"""
    ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼
    
    å¤„ç†ç»Ÿè®¡ï¼š
    {json.dumps(report['statistics'], indent=2, ensure_ascii=False)}
    
    è¯¦ç»†æŠ¥å‘Šï¼š{report_file}
    """
    
    # å‘é€é‚®ä»¶ï¼ˆéœ€è¦é…ç½®SMTPæœåŠ¡å™¨ï¼‰
    # msg = MIMEText(body)
    # msg['Subject'] = subject
    # ... é‚®ä»¶å‘é€é€»è¾‘
    
    print("ä»»åŠ¡å®Œæˆé€šçŸ¥å·²å‘é€")

# åœ¨æµæ°´çº¿å®Œæˆåè°ƒç”¨
# send_completion_email('data/results/pipeline_report.json')
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. æ•°æ®å‡†å¤‡
- ç¡®ä¿PDFæ–‡ä»¶è´¨é‡è‰¯å¥½ï¼Œæ–‡å­—æ¸…æ™°
- æŒ‰ä¸“ä¸šé¢†åŸŸåˆ†ç±»ç»„ç»‡æ–‡ä»¶
- å®šæœŸæ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œç¼“å­˜

### 2. å‚æ•°è°ƒä¼˜
- æ ¹æ®ç¡¬ä»¶æ€§èƒ½è°ƒæ•´ `batch_size` å’Œ `pool_size`
- æ ¹æ®è´¨é‡è¦æ±‚è®¾ç½® `quality_threshold`
- å¤§æ•°æ®é‡æ—¶ä½¿ç”¨åˆ†æ­¥å¤„ç†

### 3. è´¨é‡æ§åˆ¶
- å§‹ç»ˆå¯ç”¨è´¨é‡æ£€æŸ¥
- å®šæœŸäººå·¥æŠ½æ£€ç»“æœè´¨é‡
- æ ¹æ®åé¦ˆè°ƒæ•´promptå’Œå‚æ•°

### 4. æ€§èƒ½ä¼˜åŒ–
- ä½¿ç”¨SSDå­˜å‚¨æé«˜I/Oæ€§èƒ½
- åˆç†è®¾ç½®å¹¶å‘æ•°é‡é¿å…è¿‡è½½
- å®šæœŸæ¸…ç†æ—¥å¿—å’Œä¸´æ—¶æ–‡ä»¶

### 5. ç›‘æ§å’Œç»´æŠ¤
- è®¾ç½®æ—¥å¿—è½®è½¬é¿å…æ—¥å¿—æ–‡ä»¶è¿‡å¤§
- ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
- å¤‡ä»½é‡è¦çš„é…ç½®å’Œç»“æœæ–‡ä»¶

---

**éœ€è¦æ›´å¤šå¸®åŠ©ï¼Ÿ** è¯·æŸ¥çœ‹ `README.md` æˆ–ä½¿ç”¨ `./quick_start.sh` è·å–äº¤äº’å¼å¸®åŠ©ã€‚